{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "MA6O_BVtCbPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar las librerías necesarias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Preprocesamiento y modelado\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Manejo del desbalance de clases\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Métricas de evaluación\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Ignorar advertencias\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Paso 1: Cargar datos desde un archivo CSV\n",
        "df = pd.read_csv('/content/drive/MyDrive/dataset.csv')\n",
        "\n",
        "# Paso 2: División de datos de entrenamiento y prueba\n",
        "X = df['name']\n",
        "y = df['category']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Paso 3: Eliminar filas con NaN en y_train y sus correspondientes en X_train\n",
        "train_data = pd.DataFrame({'name': X_train, 'category': y_train})\n",
        "train_data = train_data.dropna()\n",
        "X_train = train_data['name']\n",
        "y_train = train_data['category']\n",
        "\n",
        "# Paso 4: Vectorización usando TF-IDF (análisis de caracteres n-grama)\n",
        "vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(2, 4))\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Paso 5: Ingeniería de características adicionales\n",
        "# Funciones auxiliares para calcular características\n",
        "def count_digits(s):\n",
        "    return sum(c.isdigit() for c in s)\n",
        "\n",
        "def count_special_chars(s):\n",
        "    return sum(not c.isalnum() for c in s)\n",
        "\n",
        "def vowel_consonant_ratio(s):\n",
        "    vowels = 'aeiouAEIOU'\n",
        "    num_vowels = sum(c in vowels for c in s)\n",
        "    num_consonants = sum(c.isalpha() and c not in vowels for c in s)\n",
        "    return num_vowels / num_consonants if num_consonants != 0 else 0\n",
        "\n",
        "# Calcular características adicionales para el conjunto de entrenamiento\n",
        "X_train_length = X_train.apply(len)\n",
        "X_train_digit_count = X_train.apply(count_digits)\n",
        "X_train_special_count = X_train.apply(count_special_chars)\n",
        "X_train_vowel_ratio = X_train.apply(vowel_consonant_ratio)\n",
        "\n",
        "# Calcular características adicionales para el conjunto de prueba\n",
        "X_test_length = X_test.apply(len)\n",
        "X_test_digit_count = X_test.apply(count_digits)\n",
        "X_test_special_count = X_test.apply(count_special_chars)\n",
        "X_test_vowel_ratio = X_test.apply(vowel_consonant_ratio)\n",
        "\n",
        "# Combinar las características adicionales en matrices numpy\n",
        "additional_features_train = np.vstack([X_train_length, X_train_digit_count, X_train_special_count, X_train_vowel_ratio]).T\n",
        "additional_features_test = np.vstack([X_test_length, X_test_digit_count, X_test_special_count, X_test_vowel_ratio]).T\n",
        "\n",
        "# Combinar las características TF-IDF con las adicionales\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "\n",
        "X_train_combined = hstack([X_train_tfidf, csr_matrix(additional_features_train)])\n",
        "X_test_combined = hstack([X_test_tfidf, csr_matrix(additional_features_test)])\n",
        "\n",
        "# Paso 6: Manejo del desbalance de clases usando SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_combined, y_train)\n",
        "\n",
        "# Paso 7: Entrenamiento del modelo con Random Forest ajustando class_weight\n",
        "model = RandomForestClassifier(n_estimators=200, class_weight='balanced', random_state=42)\n",
        "model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Paso 8: Predicciones y evaluación del modelo\n",
        "y_pred = model.predict(X_test_combined)\n",
        "\n",
        "# Métricas de evaluación\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Matriz de Confusión:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Paso 9: Validación cruzada\n",
        "scores = cross_val_score(model, X_train_resampled, y_train_resampled, cv=5, scoring='f1_macro')\n",
        "print(\"\\nF1-score promedio en validación cruzada:\", scores.mean())\n",
        "\n",
        "# Paso 10: Análisis de importancia de características\n",
        "importances = model.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "print(\"\\nLas 10 características más importantes:\")\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "num_tfidf_features = len(feature_names)\n",
        "\n",
        "for f in range(10):\n",
        "    if indices[f] < num_tfidf_features:\n",
        "        feature_name = feature_names[indices[f]]\n",
        "    else:\n",
        "        additional_index = indices[f] - num_tfidf_features\n",
        "        if additional_index == 0:\n",
        "            feature_name = 'length'\n",
        "        elif additional_index == 1:\n",
        "            feature_name = 'digit_count'\n",
        "        elif additional_index == 2:\n",
        "            feature_name = 'special_char_count'\n",
        "        elif additional_index == 3:\n",
        "            feature_name = 'vowel_consonant_ratio'\n",
        "        else:\n",
        "            feature_name = 'unknown'\n",
        "    print(f\"{f + 1}. Feature '{feature_name}' ({importances[indices[f]]})\")\n",
        "\n",
        "# Paso 11: Función para probar el modelo con nuevos nombres\n",
        "def classify_names(names):\n",
        "    # Asegurarse de que 'names' sea una lista\n",
        "    if isinstance(names, str):\n",
        "        names = [names]\n",
        "    elif not isinstance(names, list):\n",
        "        names = list(names)\n",
        "\n",
        "    # Vectorización de los nuevos nombres\n",
        "    names_tfidf = vectorizer.transform(names)\n",
        "\n",
        "    # Cálculo de características adicionales\n",
        "    names_length = [len(name) for name in names]\n",
        "    names_digit_count = [count_digits(name) for name in names]\n",
        "    names_special_count = [count_special_chars(name) for name in names]\n",
        "    names_vowel_ratio = [vowel_consonant_ratio(name) for name in names]\n",
        "\n",
        "    additional_features = np.vstack([names_length, names_digit_count, names_special_count, names_vowel_ratio]).T\n",
        "\n",
        "    # Combinar características\n",
        "    names_combined = hstack([names_tfidf, csr_matrix(additional_features)])\n",
        "\n",
        "    # Realizar predicciones\n",
        "    predictions = model.predict(names_combined)\n",
        "\n",
        "    # Devolver resultados\n",
        "    for name, prediction in zip(names, predictions):\n",
        "        print(f\"Nombre: '{name}' => Clasificación: '{prediction}'\")\n",
        "\n",
        "# Ejemplos de uso de la función classify_names\n",
        "print(\"\\nPruebas con nuevos nombres:\")\n",
        "test_names = [\n",
        "    'skrillex',\n",
        "    'dourat',\n",
        "    'dragonxx',\n",
        "    'ywhuhsus8nj',\n",
        "    'opojwrjwjos12',\n",
        "    'blackmamba',\n",
        "    'xj92kdkls',\n",
        "    'phantomfox',\n",
        "    'abc123',\n",
        "    'xypqrs',\n",
        "    'supermalware',\n",
        "    'randomname'\n",
        "]\n",
        "\n",
        "classify_names(test_names)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mT-zQtYBKlAa",
        "outputId": "c5202a33-50da-4b5a-d735-3e56eac08cdb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9250585480093677\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     generic       0.95      0.93      0.94       254\n",
            "         new       0.89      0.92      0.91       173\n",
            "\n",
            "    accuracy                           0.93       427\n",
            "   macro avg       0.92      0.93      0.92       427\n",
            "weighted avg       0.93      0.93      0.93       427\n",
            "\n",
            "Matriz de Confusión:\n",
            " [[235  19]\n",
            " [ 13 160]]\n",
            "\n",
            "F1-score promedio en validación cruzada: 0.9563726650905217\n",
            "\n",
            "Las 10 características más importantes:\n",
            "1. Feature 'digit_count' (0.05357759759344331)\n",
            "2. Feature 'vowel_consonant_ratio' (0.0456245067492046)\n",
            "3. Feature 'length' (0.04267565790545367)\n",
            "4. Feature 'er' (0.01474898477198885)\n",
            "5. Feature 'ra' (0.010473824151821244)\n",
            "6. Feature 'in' (0.00964771497855725)\n",
            "7. Feature 'at' (0.008926079416604815)\n",
            "8. Feature 'mr' (0.008743719478806106)\n",
            "9. Feature 'ff' (0.008360634916843438)\n",
            "10. Feature 'or' (0.008312116291122938)\n",
            "\n",
            "Pruebas con nuevos nombres:\n",
            "Nombre: 'skrillex' => Clasificación: 'new'\n",
            "Nombre: 'dourat' => Clasificación: 'new'\n",
            "Nombre: 'dragonxx' => Clasificación: 'new'\n",
            "Nombre: 'ywhuhsus8nj' => Clasificación: 'generic'\n",
            "Nombre: 'opojwrjwjos12' => Clasificación: 'generic'\n",
            "Nombre: 'blackmamba' => Clasificación: 'new'\n",
            "Nombre: 'xj92kdkls' => Clasificación: 'generic'\n",
            "Nombre: 'phantomfox' => Clasificación: 'new'\n",
            "Nombre: 'abc123' => Clasificación: 'generic'\n",
            "Nombre: 'xypqrs' => Clasificación: 'generic'\n",
            "Nombre: 'supermalware' => Clasificación: 'new'\n",
            "Nombre: 'randomname' => Clasificación: 'new'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Paso 11: Función para probar el modelo con nuevos nombres\n",
        "def classify_names(names):\n",
        "    # Asegurarse de que 'names' sea una lista\n",
        "    if isinstance(names, str):\n",
        "        names = [names]\n",
        "    elif not isinstance(names, list):\n",
        "        names = list(names)\n",
        "\n",
        "    # Vectorización de los nuevos nombres\n",
        "    names_tfidf = vectorizer.transform(names)\n",
        "\n",
        "    # Cálculo de características adicionales\n",
        "    names_length = [len(name) for name in names]\n",
        "    names_digit_count = [count_digits(name) for name in names]\n",
        "    names_special_count = [count_special_chars(name) for name in names]\n",
        "    names_vowel_ratio = [vowel_consonant_ratio(name) for name in names]\n",
        "\n",
        "    additional_features = np.vstack([names_length, names_digit_count, names_special_count, names_vowel_ratio]).T\n",
        "\n",
        "    # Combinar características\n",
        "    names_combined = hstack([names_tfidf, csr_matrix(additional_features)])\n",
        "\n",
        "    # Realizar predicciones\n",
        "    predictions = model.predict(names_combined)\n",
        "\n",
        "    # Devolver resultados\n",
        "    for name, prediction in zip(names, predictions):\n",
        "        print(f\"Nombre: '{name}' => Clasificación: '{prediction}'\")\n",
        "\n",
        "# Ejemplos de uso de la función classify_names\n",
        "print(\"\\nPruebas con nuevos nombres:\")\n",
        "test_names = [\n",
        "    'uwywquyuwqs125',\n",
        "    'federat',\n",
        "    'ltq0',\n",
        "    'souldarker',\n",
        "    'noolsddos',\n",
        "    'rtto',\n",
        "    'nvsrimm',\n",
        "    'tu1qwtuxxwooknxbsinzhupkxxjn',\n",
        "    'fiummmm'\n",
        "]\n",
        "\n",
        "classify_names(test_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vCTFDZHKloO",
        "outputId": "fb49675f-0599-4d1b-8e14-2df8deec5742"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Pruebas con nuevos nombres:\n",
            "Nombre: 'uwywquyuwqs125' => Clasificación: 'generic'\n",
            "Nombre: 'federat' => Clasificación: 'new'\n",
            "Nombre: 'ltq0' => Clasificación: 'generic'\n",
            "Nombre: 'souldarker' => Clasificación: 'new'\n",
            "Nombre: 'noolsddos' => Clasificación: 'new'\n",
            "Nombre: 'rtto' => Clasificación: 'generic'\n",
            "Nombre: 'nvsrimm' => Clasificación: 'generic'\n",
            "Nombre: 'tu1qwtuxxwooknxbsinzhupkxxjn' => Clasificación: 'generic'\n",
            "Nombre: 'fiummmm' => Clasificación: 'new'\n"
          ]
        }
      ]
    }
  ]
}